{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import wasserstein_distance\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "from scipy.stats import ttest_1samp\n",
    "from statistics import mean\n",
    "import random\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['gpt-3.5-turbo', 'gpt-3.5-turbo-instruct', 'llama2-7b', 'llama2-13b', 'llama2-70b', 'llama2-7b-chat', 'llama2-13b-chat', 'llama2-70b-chat', 'llama2-70b-ift']\n",
    "bias_types = ['acquiescence','response_order', 'odd_even', 'opinion_float', 'allow_forbid']\n",
    "subset_bias_types = ['acquiescence-50','response_order-50', 'odd_even-50', 'opinion_float-50', 'allow_forbid']\n",
    "perturbations = ['-key_typo', '-middle_random', '-letter_swap']\n",
    "clean_bias_labels = ['Acquiescence', 'Response Order', 'Odd/even', 'Opinion Float', 'Allow/forbid']\n",
    "\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for model in models:\n",
    "    print(model)\n",
    "\n",
    "    for i in range(len(bias_types)):\n",
    "    \n",
    "        bias_type = bias_types[i]\n",
    "        \n",
    "        print(bias_type)\n",
    "        \n",
    "        values, p_value, keys = run_stat_test(model, bias_type)\n",
    "        diff = mean(values)\n",
    "        lst = [model, clean_bias_labels[i], diff, p_value]\n",
    "        \n",
    "        for perturbation in perturbations:\n",
    "                \n",
    "            if subset_bias_types[i] == 'opinion_float-50': #qustions are the same\n",
    "                bias_type = 'odd_even'+perturbation\n",
    "            else:\n",
    "                bias_type = bias_types[i]+perturbation\n",
    "\n",
    "            values, p_value, keys = run_stat_test(model, bias_type)\n",
    "            diff = mean(values)\n",
    "            lst.append(diff)\n",
    "            lst.append(p_value)\n",
    "        \n",
    "        all_results.append(lst)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(all_results, columns = ['model', 'bias type', 'modified', 'bias p value',\\\n",
    "                                          'key typo', 'key typo p value',\\\n",
    "                                          'middle random', 'middle random p value',\\\n",
    "                                          'letter swap', 'letter swap p value'])\n",
    "df = df.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"full_results.pkl\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS PLOTS FULL RESULTS\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "np.bool = np.bool_\n",
    "\n",
    "models = ['ideal', 'llama2-7b', 'llama2-13b', 'llama2-70b', 'llama2-70b-ift', 'llama2-7b-chat', 'llama2-13b-chat', 'llama2-70b-chat', 'gpt-3.5-turbo', 'gpt-3.5-turbo-instruct']\n",
    "bias_types = ['acquiescence','allow_forbid', 'response_order', 'opinion_float', 'odd_even']\n",
    "perturbations = ['-key_typo', '-middle_random', '-letter_swap']\n",
    "exp_settings = ['modified', 'key typo', 'middle random', 'letter swap']\n",
    "clean_labels = ['bias', 'key typo', 'middle random', 'letter swap']\n",
    "clean_bias_labels = ['Acquiescence', 'Allow/forbid', 'Response Order', 'Opinion Float', 'Odd/even']\n",
    "clean_model_labels = ['Most Human-like', 'Llama2-7b', 'Llama2-13b', 'Llama2-70b', 'Solar', 'Llama-7b-chat', 'Llama-13b-chat','Llama-70b-chat', '3.5 Turbo', '3.5 Turbo Instruct']\n",
    "\n",
    "fig, axs = plt.subplots(2, len(models)//2, figsize=(15,6))\n",
    "\n",
    "cmap_name = 'tab20c'\n",
    "\n",
    "for i in range(len(models)):\n",
    "    \n",
    "    model = models[i]\n",
    "    \n",
    "    effect_data = np.zeros((len(bias_types),len(exp_settings)))\n",
    "    p_values = np.zeros((len(bias_types),len(exp_settings)))\n",
    "    \n",
    "    for k in range(len(exp_settings)):\n",
    "        for j in range(len(bias_types)):\n",
    "            \n",
    "            exp_setting = exp_settings[k]\n",
    "                        \n",
    "            if exp_setting == 'modified':\n",
    "                p_val_col = 'bias p value'\n",
    "\n",
    "            elif exp_setting ==\"key typo\":\n",
    "                p_val_col = 'key typo p value'\n",
    "            \n",
    "            elif exp_setting == \"middle random\":\n",
    "                p_val_col = 'middle random p value'\n",
    "            \n",
    "            elif exp_setting == \"letter swap\":\n",
    "                p_val_col = 'letter swap p value'\n",
    "            \n",
    "            \n",
    "            if model == 'ideal':\n",
    "                if k == 0:\n",
    "                    effect_size = random.uniform(0, 1)\n",
    "                    p_value = 0.01\n",
    "                else:\n",
    "                    effect_size = 1\n",
    "                    p_value = 1\n",
    "\n",
    "\n",
    "                if p_value < 0.05:\n",
    "                    effect_data[j][k] = -0.7\n",
    "                else:\n",
    "                    effect_data[j][k] = np.nan\n",
    "\n",
    "                p_values[j][k] = p_value\n",
    "\n",
    "            else:\n",
    "                effect_size = df[(df['bias type'] == clean_bias_labels[j])\\\n",
    "                                                &(df['model']==model)][exp_setting]\n",
    "                p_value = df[(df['bias type'] == clean_bias_labels[j])\\\n",
    "                                                &(df['model']==model)][p_val_col]\n",
    "\n",
    "                p_values[j][k] = p_value.item()\n",
    "                if p_value.item() < 0.05:\n",
    "                    if effect_size.item() > 0:\n",
    "                        effect_data[j][k] = -0.7\n",
    "                    else:\n",
    "                        effect_data[j][k] = -0.3\n",
    "                else:\n",
    "                    effect_data[j][k] = np.nan\n",
    "\n",
    "    r = i//5\n",
    "    c = i%5\n",
    "    \n",
    "         \n",
    "    if r == 0 and c== 0:\n",
    "        sns.heatmap(effect_data, xticklabels=False, cbar=False, ax=axs[r,c], cmap=cmap_name, vmin=-1, vmax=1, linewidths=1, linecolor='gray')  \n",
    "        tickvalues = [num+0.5 for num in range(0,len(exp_settings))]\n",
    "        axs[r,c].set_title(clean_model_labels[i])\n",
    "        \n",
    "        tickvalues1 = [num+0.5 for num in range(0,len(bias_types))]\n",
    "        axs[r,c].set_yticks(tickvalues1)\n",
    "        axs[r,c].set_yticklabels(clean_bias_labels, rotation=0)\n",
    "        \n",
    "    if r == 0 and c!= 0:\n",
    "        sns.heatmap(effect_data, xticklabels=False, yticklabels=False, cbar=False, ax=axs[r,c], cmap=cmap_name, vmin=-1, vmax=1, linewidths=1, linecolor='gray')  \n",
    "        axs[r,c].set_title(clean_model_labels[i])\n",
    "        \n",
    "    if r == 1 and c== 0:\n",
    "        sns.heatmap(effect_data, cbar=False, ax=axs[r,c], cmap=cmap_name, vmin=-1, vmax=1, linewidths=1, linecolor='gray')  \n",
    "        tickvalues = [num+0.5 for num in range(0,len(exp_settings))]\n",
    "        axs[r,c].set_xticks(tickvalues)\n",
    "        axs[r,c].set_xticklabels(clean_labels, rotation=90)\n",
    "        axs[r,c].set_title(clean_model_labels[i])\n",
    "        \n",
    "        tickvalues1 = [num+0.5 for num in range(0,len(bias_types))]\n",
    "        axs[r,c].set_yticks(tickvalues1)\n",
    "        axs[r,c].set_yticklabels(clean_bias_labels, rotation=0)\n",
    "        \n",
    "    if r == 1 and c!= 0:\n",
    "        sns.heatmap(effect_data, yticklabels=False, cbar=False, ax=axs[r,c], cmap=cmap_name, vmin=-1, vmax=1, linewidths=1, linecolor='gray')  \n",
    "        tickvalues = [num+0.5 for num in range(0,len(exp_settings))]\n",
    "        axs[r,c].set_xticks(tickvalues)\n",
    "        axs[r,c].set_xticklabels(clean_labels, rotation=90)\n",
    "        axs[r,c].set_title(clean_model_labels[i])\n",
    "        \n",
    "    zm = np.ma.masked_less(p_values, 0.05)\n",
    "            \n",
    "    x= np.arange(effect_data.shape[1]+1)\n",
    "    y= np.arange(effect_data.shape[0]+1)\n",
    "\n",
    "    axs[r,c].pcolor(x, y, zm, hatch='//', alpha=0.)\n",
    "\n",
    "\n",
    "plt.savefig(\"perturbation.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
